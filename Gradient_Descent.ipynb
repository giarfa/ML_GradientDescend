{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient Descent.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBuwBq5mXzUBRAwc/oGaxH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giarfa/ML_GradientDescend/blob/master/Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzDdCm0GNAyM",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Descent simple example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-_SRr9aNiY9",
        "colab_type": "code",
        "outputId": "7f6d4618-36a3-41c3-ebbc-742f23ae5553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!git clone https://github.com/mattnedrich/GradientDescentExample.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'GradientDescentExample' already exists and is not an empty directory.\n",
            "GradientDescentExample\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwNKGv_TOBqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGsKygy4U1UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(actual_m, actual_b, points, learning_rate):\n",
        "  gradient_m = 0\n",
        "  gradient_b = 0\n",
        "  N = float(len(points))\n",
        "  for i in range(len(points)):\n",
        "    x = points[i, 0]\n",
        "    y = points[i, 1]\n",
        "    gradient_m += -(2/N) * x * (y - ((actual_m * x) + actual_b))\n",
        "    gradient_b += -(2/N) * (y - ((actual_m * x) + actual_b))\n",
        "  new_m = actual_m - (gradient_m * learning_rate)\n",
        "  new_b = actual_b - (gradient_b * learning_rate)\n",
        "  return new_m, new_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbZOBUEGU6Ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent_runner(initial_m, initial_b, points, learning_rate, num_iterations):\n",
        "  m = initial_m\n",
        "  b = initial_b\n",
        "  for i in range(num_iterations):\n",
        "    m, b = gradient_descent(m, b, points, learning_rate)\n",
        "  return m, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeX9tGTtV7na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_error(m, b, points):\n",
        "  error = 0\n",
        "  for i in range(len(points)):\n",
        "    x = points[i, 0]\n",
        "    y = points[i, 1]\n",
        "    error += (y - (m * x + b)) ** 2\n",
        "  return error / float(len(points))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWafFS2FWrwM",
        "colab_type": "code",
        "outputId": "f593377d-6c8b-4504-836d-3bb2ba24e6d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "points = genfromtxt(\"./GradientDescentExample/data.csv\", delimiter=\",\")\n",
        "\n",
        "initial_error = compute_error(0, 0, points)\n",
        "print(\"INITIAL => m: {0}, b: {1}, error: {2}\".format(0, 0, initial_error))\n",
        "\n",
        "m, b = gradient_descent_runner(0, 0, points, learning_rate=0.0001, num_iterations=1)\n",
        "error = compute_error(m, b, points)\n",
        "print(\"1 ITERATION => m: {0}, b: {1}, error: {2}\".format(m, b, error))\n",
        "\n",
        "m, b = gradient_descent_runner(0, 0, points, learning_rate=0.0001, num_iterations=10)\n",
        "error = compute_error(m, b, points)\n",
        "print(\"10 ITERATIONS => m: {0}, b: {1}, error: {2}\".format(m, b, error))\n",
        "\n",
        "m, b = gradient_descent_runner(0, 0, points, learning_rate=0.0001, num_iterations=100)\n",
        "error = compute_error(m, b, points)\n",
        "print(\"100 ITERATIONS => m: {0}, b: {1}, error: {2}\".format(m, b, error))\n",
        "\n",
        "m, b = gradient_descent_runner(0, 0, points, learning_rate=0.0001, num_iterations=1000)\n",
        "error = compute_error(m, b, points)\n",
        "print(\"1000 ITERATIONS => m: {0}, b: {1}, error: {2}\".format(m, b, error))\n",
        "\n",
        "m, b = gradient_descent_runner(0, 0, points, learning_rate=0.0001, num_iterations=10000)\n",
        "error = compute_error(m, b, points)\n",
        "print(\"10000 ITERATIONS => m: {0}, b: {1}, error: {2}\".format(m, b, error))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INITIAL => m: 0, b: 0, error: 5565.107834483211\n",
            "1 ITERATION => m: 0.7370702973591052, b: 0.014547010110737297, error: 1484.586557408649\n",
            "10 ITERATIONS => m: 1.4774173755483797, b: 0.02963934787473239, error: 112.65585181499746\n",
            "100 ITERATIONS => m: 1.4788027175308358, b: 0.03507497059234178, error: 112.64705664288809\n",
            "1000 ITERATIONS => m: 1.4777440851894448, b: 0.08893651993741346, error: 112.61481011613473\n",
            "10000 ITERATIONS => m: 1.4675440436333027, b: 0.6078985997054931, error: 112.31533427075733\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}